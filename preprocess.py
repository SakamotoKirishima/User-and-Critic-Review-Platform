# -*- coding: utf-8 -*-
"""preProcess.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MiTnXMZOyLSYqFHX8aqVHtDe4Y1gaN8Y
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.preprocessing import MinMaxScaler
import pymongo
import argparse

parser = argparse.ArgumentParser()
parser.add_argument('collection')
# parser.add_argument('id')
parser.add_argument('ratings_collection')
parser.add_argument('join_column')
parser.add_argument('title')
parser.add_argument('rating')
parser.add_argument('user_id')
args = parser.parse_args()
client = pymongo.MongoClient(
    'mongodb+srv://mathangi_s:Meenakshi12@cluster0-mvtbq.mongodb.net/test?retryWrites=true&w=majority')
print(client.list_database_names())
db = client.critle
print(db.collection_names())
musicData = list(db[args.collection].find({}))
musicDataValues = list()

for row in musicData:
    rowValues = row.values()
    musicDataValues.append(rowValues)
music = pd.DataFrame(musicDataValues, columns=musicData[0].keys())
music = music.drop(['_id'], axis=1)
print(music)
# print(args.rating_collection)
# exit()
ratingData = list(db[args.ratings_collection].find({}))
musicRatingDataValues = list()
for row in ratingData:
    rowValues = row.values()
    musicRatingDataValues.append(rowValues)
rating = pd.DataFrame(musicRatingDataValues, columns=ratingData[0].keys())
rating = rating.drop(['_id'], axis=1)
print(rating)
# exit()
# rating = pd.read_csv('ratings_small.csv')
# rating = pd.read_csv('BX-Book-Ratings.csv', sep=';', error_bad_lines=False, encoding="latin-1")
# user = pd.read_csv('BX-Users.csv', sep=';', error_bad_lines=False, encoding="latin-1")
# book = pd.read_csv('BX-Books.csv', sep=';', error_bad_lines=False, encoding="latin-1")
# movies= pd.read_csv('allData.csv')
# movies.columns
music_rating = pd.merge(rating, music, on=args.join_column)
# book_rating = pd.merge(rating, book, on='ISBN')
# cols = ['Year-Of-Publication', 'Publisher', 'Book-Author', 'Image-URL-S', 'Image-URL-M', 'Image-URL-L']
# book_rating.drop(cols, axis=1, inplace=True)
# print(rating.describe())
# print(user.describe())
# print(book.describe())
print(music_rating.head())
# exit()
rating_count = (
    music_rating.groupby(by=[args.title])[args.rating].count().reset_index().rename(
        columns={args.rating: 'rating_count_art'})[[args.title, 'rating_count_art']])

threshold = 25
rating_count = rating_count.query('rating_count_art >= @threshold')

user_rating = pd.merge(rating_count, music_rating, left_on=args.title, right_on=args.title, how='left')
print(user_rating)
user_count = (
    user_rating.groupby(by=[args.user_id])[args.rating].count().reset_index().rename(
        columns={args.rating: 'RatingCount_user'})[[args.user_id, 'RatingCount_user']])

threshold = 10
user_count = user_count.query('RatingCount_user >= @threshold')

combined = user_rating.merge(user_count, left_on=args.user_id, right_on=args.user_id, how='inner')
# print(combined)
# exit()
print('Number of unique artworks: ', combined[args.title].nunique())
print('Number of unique users: ', combined[args.user_id].nunique())
# exit()
scaler = MinMaxScaler()
combined[args.rating] = combined[args.rating].values.astype(float)
rating_scaled = pd.DataFrame(scaler.fit_transform(combined[args.rating].values.reshape(-1, 1)))
combined[args.rating] = rating_scaled

combined = combined.drop_duplicates([args.user_id, args.title])
user_music_matrix = combined.pivot(index=args.user_id, columns=args.title, values=args.rating)
user_music_matrix.fillna(0, inplace=True)
users = user_music_matrix.index.tolist()
books = user_music_matrix.columns.tolist()
user_music_matrix = user_music_matrix.values

import tensorflow.compat.v1 as tf

tf.disable_v2_behavior()
num_input = combined[args.title].nunique()
num_hidden_1 = 10
num_hidden_2 = 5

X = tf.placeholder(tf.float64, [None, num_input])

weights = {
    'encoder_h1': tf.Variable(tf.random_normal([num_input, num_hidden_1], dtype=tf.float64)),
    'encoder_h2': tf.Variable(tf.random_normal([num_hidden_1, num_hidden_2], dtype=tf.float64)),
    'decoder_h1': tf.Variable(tf.random_normal([num_hidden_2, num_hidden_1], dtype=tf.float64)),
    'decoder_h2': tf.Variable(tf.random_normal([num_hidden_1, num_input], dtype=tf.float64)),
}

biases = {
    'encoder_b1': tf.Variable(tf.random_normal([num_hidden_1], dtype=tf.float64)),
    'encoder_b2': tf.Variable(tf.random_normal([num_hidden_2], dtype=tf.float64)),
    'decoder_b1': tf.Variable(tf.random_normal([num_hidden_1], dtype=tf.float64)),
    'decoder_b2': tf.Variable(tf.random_normal([num_input], dtype=tf.float64)),
}


def encoder(x):
    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['encoder_h1']), biases['encoder_b1']))
    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['encoder_h2']), biases['encoder_b2']))
    return layer_2


def decoder(x):
    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['decoder_h1']), biases['decoder_b1']))
    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['decoder_h2']), biases['decoder_b2']))
    return layer_2


encoder_op = encoder(X)
decoder_op = decoder(encoder_op)
y_pred = decoder_op
y_true = X
print(y_pred)
loss = tf.losses.mean_squared_error(y_true, y_pred)
optimizer = tf.train.RMSPropOptimizer(0.03).minimize(loss)
eval_x = tf.placeholder(tf.int32, )
eval_y = tf.placeholder(tf.int32, )
pre, pre_op = tf.metrics.precision(labels=eval_x, predictions=eval_y)
init = tf.global_variables_initializer()
local_init = tf.local_variables_initializer()
pred_data = pd.DataFrame()
saver = tf.train.Saver()
with tf.Session() as session:
    epochs = 100
    batch_size = 35

    session.run(init)
    session.run(local_init)

    num_batches = int(user_music_matrix.shape[0] / batch_size)
    user_music_matrix = np.array_split(user_music_matrix, num_batches)

    for i in range(epochs):

        avg_cost = 0
        for batch in user_music_matrix:
            _, l = session.run([optimizer, loss], feed_dict={X: batch})
            avg_cost += l

        avg_cost /= num_batches

        print("epoch: {} Loss: {}".format(i + 1, avg_cost))

    user_music_matrix = np.concatenate(user_music_matrix, axis=0)

    preds = session.run(decoder_op, feed_dict={X: user_music_matrix})

    pred_data = pred_data.append(pd.DataFrame(preds))

    pred_data = pred_data.stack().reset_index(name=args.rating)
    pred_data.columns = [args.user_id, args.title, args.rating]
    pred_data[args.user_id] = pred_data[args.user_id].map(lambda value: users[value])
    pred_data[args.title] = pred_data[args.title].map(lambda value: books[value])

    keys = [args.user_id, args.title]
    index_1 = pred_data.set_index(keys).index
    index_2 = combined.set_index(keys).index

    top_ten_ranked = pred_data[~index_1.isin(index_2)]
    top_ten_ranked = top_ten_ranked.sort_values([args.user_id, args.rating], ascending=[True, False])
    top_ten_ranked = top_ten_ranked.groupby(args.user_id).head(10)
    save_path = saver.save(session, "modelMusic.ckpt")
print(top_ten_ranked.loc[top_ten_ranked[args.user_id] == 27])
print(music_rating.loc[music_rating[args.user_id] == 27].sort_values(by=[args.rating], ascending=False))
